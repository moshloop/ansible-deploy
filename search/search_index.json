{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opionated role for creating shortcuts for various ansible tasks Design Principles/Goals Multi-targeting - The ability to take the same manifest and deploy it to different target environments Convention over configuration - Only require the most minimal set of information to deploy. Batteries included - Implement best practises by default, switch to vania Composable - Multiple and complex environments are assumed. e.g. It should be easy to share manifest between staging and production while at the same time allowing central IT to inject dependencies into multiple deployment manifests to enforce standards. Multi-Targeting Supported targets Ansible AWS ECS cloudinit Roadmap Kubernetes Swarm Inventory Model Hooks","title":"Getting Started"},{"location":"#design-principlesgoals","text":"Multi-targeting - The ability to take the same manifest and deploy it to different target environments Convention over configuration - Only require the most minimal set of information to deploy. Batteries included - Implement best practises by default, switch to vania Composable - Multiple and complex environments are assumed. e.g. It should be easy to share manifest between staging and production while at the same time allowing central IT to inject dependencies into multiple deployment manifests to enforce standards.","title":"Design Principles/Goals"},{"location":"#multi-targeting","text":"","title":"Multi-Targeting"},{"location":"#supported-targets","text":"Ansible AWS ECS cloudinit","title":"Supported targets"},{"location":"#roadmap","text":"Kubernetes Swarm","title":"Roadmap"},{"location":"#inventory-model","text":"","title":"Inventory Model"},{"location":"#hooks","text":"","title":"Hooks"},{"location":"ansible-addons/","text":"Filters name description dir_exists (path) file_exists (path) from_si_unit (number, base_unit) Converts a SI unit e.g. 1GB into a number with an optional base is_empty (val) jsonpath (data) transforms data using jsonpath_rw map_to_entries (dict, key, value) Convert a dict into a list of entries nestedelement (path) Returns an nested element from an object tree by path (seperated by / or .) play_groups (play_hosts, groups, hostvars) Returns a list of groups that are active within a play split (string, separator=' ') sub_map (dict, prefix) Filter a map by key prefix and remove prefix from keys to_map (map, key, value) walk_up (object, path) Walks up an object tree from the lowest level collecting all attributes not available at lower levels dir_exists when : \"'/path/to/dir' | dir_exists\" file_exists when : \"'/path/to/file' | file_exists\" from_si_unit '1GB' | from_si_unit ( 'MB' ) == 1024 is_empty ' ' | is_empty == true jsonpath map_to_entries nestedelement play_groups split 'one two' | split == [ 'one' , 'two' ] to_map walk_up sub_map sub_map ({ \"elb.check\" : \"/health\" , \"elb.port\" : \"100\" , \"don.t\" : \"match\" }, \"elb.\" ) == { \"check\" : \"/health\" , \"port\" : \"100\" } Modules cloudinit_iso Example - cloudinit_iso : dest : \"{{playbook_dir}}/cloudinit.iso\" user : | #cloud-config preserve_hostname: true hostname: ansible-hostname users: - name: hostname Depdenencies genisoimage systemd_service Option Default Required Description ExecStart Yes Name Yes Description Restart on-failure RunAs root ServiceArgs A dict of key values to add under the [service] section UnitArgs A dict of key values to add under the [unit] section WantedBy multi-user.target state present Example - hosts : all roles : - moshloop.systemd tasks : - systemd_service : Name : test ExecStart : \"/usr/bin/nc -l 200\" - systemd_service : Name : test ExecStart : \"/usr/bin/nc -l 200\" UnitArgs : After : networking.service","title":"ansible-extras"},{"location":"ansible-addons/#filters","text":"name description dir_exists (path) file_exists (path) from_si_unit (number, base_unit) Converts a SI unit e.g. 1GB into a number with an optional base is_empty (val) jsonpath (data) transforms data using jsonpath_rw map_to_entries (dict, key, value) Convert a dict into a list of entries nestedelement (path) Returns an nested element from an object tree by path (seperated by / or .) play_groups (play_hosts, groups, hostvars) Returns a list of groups that are active within a play split (string, separator=' ') sub_map (dict, prefix) Filter a map by key prefix and remove prefix from keys to_map (map, key, value) walk_up (object, path) Walks up an object tree from the lowest level collecting all attributes not available at lower levels","title":"Filters"},{"location":"ansible-addons/#dir_exists","text":"when : \"'/path/to/dir' | dir_exists\"","title":"dir_exists"},{"location":"ansible-addons/#file_exists","text":"when : \"'/path/to/file' | file_exists\"","title":"file_exists"},{"location":"ansible-addons/#from_si_unit","text":"'1GB' | from_si_unit ( 'MB' ) == 1024","title":"from_si_unit"},{"location":"ansible-addons/#is_empty","text":"' ' | is_empty == true","title":"is_empty"},{"location":"ansible-addons/#jsonpath","text":"","title":"jsonpath"},{"location":"ansible-addons/#map_to_entries","text":"","title":"map_to_entries"},{"location":"ansible-addons/#nestedelement","text":"","title":"nestedelement"},{"location":"ansible-addons/#play_groups","text":"","title":"play_groups"},{"location":"ansible-addons/#split","text":"'one two' | split == [ 'one' , 'two' ]","title":"split"},{"location":"ansible-addons/#to_map","text":"","title":"to_map"},{"location":"ansible-addons/#walk_up","text":"","title":"walk_up"},{"location":"ansible-addons/#sub_map","text":"sub_map ({ \"elb.check\" : \"/health\" , \"elb.port\" : \"100\" , \"don.t\" : \"match\" }, \"elb.\" ) == { \"check\" : \"/health\" , \"port\" : \"100\" }","title":"sub_map"},{"location":"ansible-addons/#modules","text":"","title":"Modules"},{"location":"ansible-addons/#cloudinit_iso","text":"Example - cloudinit_iso : dest : \"{{playbook_dir}}/cloudinit.iso\" user : | #cloud-config preserve_hostname: true hostname: ansible-hostname users: - name: hostname Depdenencies genisoimage","title":"cloudinit_iso"},{"location":"ansible-addons/#systemd_service","text":"Option Default Required Description ExecStart Yes Name Yes Description Restart on-failure RunAs root ServiceArgs A dict of key values to add under the [service] section UnitArgs A dict of key values to add under the [unit] section WantedBy multi-user.target state present Example - hosts : all roles : - moshloop.systemd tasks : - systemd_service : Name : test ExecStart : \"/usr/bin/nc -l 200\" - systemd_service : Name : test ExecStart : \"/usr/bin/nc -l 200\" UnitArgs : After : networking.service","title":"systemd_service"},{"location":"bootstrapping/","text":"Bootstrapping Name Default Description ssh_key_user ec2-user The name of the preconfigured user in the image ssh_key_full The SSH public key to install as an authorized key for ssh_key_user git_repo git_branch master git_path /etc/repository git_account Optional: The AWS account that git_repo is hosted in git_role Optional: An IAM role in git_account that has codecommit permissions on git_repo phone_home A bash snippet that gets executed at the end of bootstrapping - e.g. To execute an initial Ansible Tower playbook run A cloud-init file is specified on launch that provides: Inserts the ssh_key_full public key into the ssh_key_user 's authorized_keys file Formats and mounts any volumes that have mount params and adds them into /etc/fstab Updates the hostname Updates /etc/environment with the role, purpose, purposeId, environment, region, domain, ami values Configures git to use the git_account/git_role IAM role for AWS CodeCommit checkouts (if specified) Clones git_repo to git_path and installs any git hooks in the .hooks directory and execute the post-merge hook. Installs a systemd service and timer git-sync that keeps the git repo in sync. Executes the script specified in phone_home","title":"Bootstrapping"},{"location":"bootstrapping/#bootstrapping","text":"Name Default Description ssh_key_user ec2-user The name of the preconfigured user in the image ssh_key_full The SSH public key to install as an authorized key for ssh_key_user git_repo git_branch master git_path /etc/repository git_account Optional: The AWS account that git_repo is hosted in git_role Optional: An IAM role in git_account that has codecommit permissions on git_repo phone_home A bash snippet that gets executed at the end of bootstrapping - e.g. To execute an initial Ansible Tower playbook run A cloud-init file is specified on launch that provides: Inserts the ssh_key_full public key into the ssh_key_user 's authorized_keys file Formats and mounts any volumes that have mount params and adds them into /etc/fstab Updates the hostname Updates /etc/environment with the role, purpose, purposeId, environment, region, domain, ami values Configures git to use the git_account/git_role IAM role for AWS CodeCommit checkouts (if specified) Clones git_repo to git_path and installs any git hooks in the .hooks directory and execute the post-merge hook. Installs a systemd service and timer git-sync that keeps the git repo in sync. Executes the script specified in phone_home","title":"Bootstrapping"},{"location":"cloudinit/","text":"","title":"Cloudinit"},{"location":"commands/","text":"commands commands : - echo 123 Shorthand for shell command \u2716 Not Supported","title":"Commands"},{"location":"commands/#commands","text":"commands : - echo 123 Shorthand for shell command \u2716 Not Supported","title":"commands"},{"location":"concepts/","text":"Inventory Model Hooks Targets","title":"Concepts"},{"location":"concepts/#inventory-model","text":"","title":"Inventory Model"},{"location":"concepts/#hooks","text":"","title":"Hooks"},{"location":"concepts/#targets","text":"","title":"Targets"},{"location":"containers/","text":"Arguments Argument Default Description image [Required] Docker image to run service The name of the systemd service env A dictionary of environment variables to pass through labels A dictionary of labels to add to the container docker_args Additional arguments to the docker client e.g. -p 8080:8080 docker_opts Additional options to the docker client e.g. -H unix:///tmp/var/run/docker.sock args Additional arguments to the container volumes List of volume mappings ports List of port mappings network user-bridge cpu mem replicas 1 play.yml - hosts : localhost roles : - deploy vars : containers : - image : nginx service : nginx env : DOMAIN : localhost.com - image : nginx service : nginx2 docker_args : -p 8080:80 Docker Compose Docker compose can also be used as a source to deploy to any target. Only the attributes listed below are supported: ports environment image deploy/limits deploy/replicas networks (Not supported on ECS) ui.labels (See Load Balancing ) group_vars/group.yml docker_compose_v3 : - files/docker-compose.yml files/docker-compose.yml version : \"3\" services : gateway : image : gateway:4.1.0-SNAPSHOT deploy : resources : limits : memory : 2G environment : - TZ=Africa/Harare ports : - \"8166:8166\" networks : - user networks : user : external : name : public Implemented as systemd services that controls container Implemented as 1 ECS container per task per service using Weave overlay","title":"Containers"},{"location":"containers/#arguments","text":"Argument Default Description image [Required] Docker image to run service The name of the systemd service env A dictionary of environment variables to pass through labels A dictionary of labels to add to the container docker_args Additional arguments to the docker client e.g. -p 8080:8080 docker_opts Additional options to the docker client e.g. -H unix:///tmp/var/run/docker.sock args Additional arguments to the container volumes List of volume mappings ports List of port mappings network user-bridge cpu mem replicas 1 play.yml - hosts : localhost roles : - deploy vars : containers : - image : nginx service : nginx env : DOMAIN : localhost.com - image : nginx service : nginx2 docker_args : -p 8080:80","title":"Arguments"},{"location":"containers/#docker-compose","text":"Docker compose can also be used as a source to deploy to any target. Only the attributes listed below are supported: ports environment image deploy/limits deploy/replicas networks (Not supported on ECS) ui.labels (See Load Balancing ) group_vars/group.yml docker_compose_v3 : - files/docker-compose.yml files/docker-compose.yml version : \"3\" services : gateway : image : gateway:4.1.0-SNAPSHOT deploy : resources : limits : memory : 2G environment : - TZ=Africa/Harare ports : - \"8166:8166\" networks : - user networks : user : external : name : public Implemented as systemd services that controls container Implemented as 1 ECS container per task per service using Weave overlay","title":"Docker Compose"},{"location":"environment/","text":"- hosts : localhost roles : - deploy vars : env_vars : httpProxy : 127.0.0.1 tasks : - name : Testing shell : \"cat /etc/environment | grep httpProxy\"","title":"Environment"},{"location":"hooks/","text":"Hooks provide a mechanism for implementing cross-cutting concerns against multiple ansible repositories / playbooks / roles. Tip Hooks are analogous to JUnit's @Before , @After .. and Jasmine's beforeEach() , afterAll() Hook Lifecycle before once hooks before each hooks group vaults \u21e8 execute \u21e6 after each hooks after once hooks Assuming group_names: all, web before.all.once.yml ( run_once: true ) before.web.once.yml ( run_once: true ) before.all.yml before.web.yml vault/all vault/web \u21e8 execute \u21e6 after.all.yml after.web.yml after.web.once.yml ( run_once: true ) after.all.once.yml ( run_once: true ) Before Before hooks are useful enhancing or transforming the inventory model, e.g inject new containers into containers or updating docker_registry with temporary credentials. before.all.once.yml vs before.all.yml After After hooks run after everything else and allows for the full use of ansible. Hook Types Tasks Task hooks are imported using include: and just run the tasks listed in the yml file. Vaults Similar to vaulted files and variables included inside an inventory, Hook vaults are only imported on-demand, i.e. if you exclude tasks via --tags or hosts via --limit then a vault password is required. This allows running a subset of a playbook without access to the vault. Hook Location Hook files can placed inside the working directory and/or from any location specified by the hooks list.","title":"Hooks"},{"location":"hooks/#hook-lifecycle","text":"before once hooks before each hooks group vaults \u21e8 execute \u21e6 after each hooks after once hooks Assuming group_names: all, web before.all.once.yml ( run_once: true ) before.web.once.yml ( run_once: true ) before.all.yml before.web.yml vault/all vault/web \u21e8 execute \u21e6 after.all.yml after.web.yml after.web.once.yml ( run_once: true ) after.all.once.yml ( run_once: true )","title":"Hook Lifecycle"},{"location":"hooks/#before","text":"Before hooks are useful enhancing or transforming the inventory model, e.g inject new containers into containers or updating docker_registry with temporary credentials. before.all.once.yml vs before.all.yml","title":"Before"},{"location":"hooks/#after","text":"After hooks run after everything else and allows for the full use of ansible.","title":"After"},{"location":"hooks/#hook-types","text":"","title":"Hook Types"},{"location":"hooks/#tasks","text":"Task hooks are imported using include: and just run the tasks listed in the yml file.","title":"Tasks"},{"location":"hooks/#vaults","text":"Similar to vaulted files and variables included inside an inventory, Hook vaults are only imported on-demand, i.e. if you exclude tasks via --tags or hosts via --limit then a vault password is required. This allows running a subset of a playbook without access to the vault.","title":"Vaults"},{"location":"hooks/#hook-location","text":"Hook files can placed inside the working directory and/or from any location specified by the hooks list.","title":"Hook Location"},{"location":"load-balancing/","text":"Loadbalancers Docker Compose Load balancers can be specified using annotations in docker-compose files: files/docker-compose.yml version : \"3\" services : ui : labels : elb.ports : \"443:8166\" elb.type : \"https:http\" elb.scheme : internet-facing elb.subnet : Public elb.healthcheck-path : \"/health\" Arguments Name Default Description port type http http,https,tcp scheme internal internet-facing subnet {{subnet_name}} healthcheck-path / healthcheck-port {{port}} healthcheck-protocol {{type}} certificate-arn security-groups","title":"Load Balancing"},{"location":"load-balancing/#loadbalancers","text":"","title":"Loadbalancers"},{"location":"load-balancing/#docker-compose","text":"Load balancers can be specified using annotations in docker-compose files: files/docker-compose.yml version : \"3\" services : ui : labels : elb.ports : \"443:8166\" elb.type : \"https:http\" elb.scheme : internet-facing elb.subnet : Public elb.healthcheck-path : \"/health\"","title":"Docker Compose"},{"location":"load-balancing/#arguments","text":"Name Default Description port type http http,https,tcp scheme internal internet-facing subnet {{subnet_name}} healthcheck-path / healthcheck-port {{port}} healthcheck-protocol {{type}} certificate-arn security-groups","title":"Arguments"},{"location":"storage/","text":"Storage mounts mounts : \"/mnt/point\" : \"nfserver:/volume\" Volumes volumes : - {} Name Default Description size Size in GB of the volume id The name of the volume e.g. volume it will be used as suffix dev The unique device path to use e.g. /dev/xvf , host:/nfs_mount type gp2 format Optional: Partition type e.g. xfs , lvm , nfs mount Optional: Mount point for the volume e.g. /mnt/volume LVM LVM volumes are supported are supported: To create an physical volume specify format: lvm and the volume name under mount: VolName Then add another volume with dev: VolName Example: create a 200GB volume called VolData, format it with xfs and then mount under /pgdata volumes : - { size : 201 , id : data , dev : /dev/xvdf , format : lvm , mount : VolData } - { size : 200 , id : data-pgdata , dev : VolData , format : xfs , mount : /pgdata } Example: Creating 3 LVM volumes for Postgres volumes : - { size : 201 , id : data , dev : /dev/xvdf , format : lvm , mount : VolData } - { size : 200 , id : data-pgdata , dev : VolData , format : xfs , mount : /pgdata } - { size : 101 , id : backups , dev : /dev/xvdg , format : lvm , mount : VolBackups } - { size : 100 , id : backups-data , dev : VolBackups , format : xfs , mount : /pgbackups } - { size : 51 , id : wal , dev : /dev/xvdh , format : lvm , mount : VolWAL } - { size : 50 , id : wal-share , dev : VolWAL , format : xfs , mount : /pgwal } result: $ df -h Filesystem Size Used Avail Use% Mounted on ... /dev/mapper/VolData-_pgdata 200G 33M 200G 1 % /pgdata /dev/mapper/VolBackups-_pgbackups 100G 33M 100G 1 % /pgbackups /dev/mapper/VolWAL-_pgwal 50G 33M 50G 1 % /pgwal Warning Due to some differences in sizing it is recommended to make LVM logical volumes 1GB smaller than the physical volume Instance Volume instance_volumes : - {} Name Default Description dev format mount","title":"Storage"},{"location":"storage/#storage","text":"","title":"Storage"},{"location":"storage/#mounts","text":"mounts : \"/mnt/point\" : \"nfserver:/volume\"","title":"mounts"},{"location":"storage/#volumes","text":"volumes : - {} Name Default Description size Size in GB of the volume id The name of the volume e.g. volume it will be used as suffix dev The unique device path to use e.g. /dev/xvf , host:/nfs_mount type gp2 format Optional: Partition type e.g. xfs , lvm , nfs mount Optional: Mount point for the volume e.g. /mnt/volume","title":"Volumes"},{"location":"storage/#lvm","text":"LVM volumes are supported are supported: To create an physical volume specify format: lvm and the volume name under mount: VolName Then add another volume with dev: VolName Example: create a 200GB volume called VolData, format it with xfs and then mount under /pgdata volumes : - { size : 201 , id : data , dev : /dev/xvdf , format : lvm , mount : VolData } - { size : 200 , id : data-pgdata , dev : VolData , format : xfs , mount : /pgdata } Example: Creating 3 LVM volumes for Postgres volumes : - { size : 201 , id : data , dev : /dev/xvdf , format : lvm , mount : VolData } - { size : 200 , id : data-pgdata , dev : VolData , format : xfs , mount : /pgdata } - { size : 101 , id : backups , dev : /dev/xvdg , format : lvm , mount : VolBackups } - { size : 100 , id : backups-data , dev : VolBackups , format : xfs , mount : /pgbackups } - { size : 51 , id : wal , dev : /dev/xvdh , format : lvm , mount : VolWAL } - { size : 50 , id : wal-share , dev : VolWAL , format : xfs , mount : /pgwal } result: $ df -h Filesystem Size Used Avail Use% Mounted on ... /dev/mapper/VolData-_pgdata 200G 33M 200G 1 % /pgdata /dev/mapper/VolBackups-_pgbackups 100G 33M 100G 1 % /pgbackups /dev/mapper/VolWAL-_pgwal 50G 33M 50G 1 % /pgwal Warning Due to some differences in sizing it is recommended to make LVM logical volumes 1GB smaller than the physical volume","title":"LVM"},{"location":"storage/#instance-volume","text":"instance_volumes : - {} Name Default Description dev format mount","title":"Instance Volume"},{"location":"sysctl/","text":"sysctl sysctls : \"vm.max_map_count\" : 262144","title":"Sysctl"},{"location":"sysctl/#sysctl","text":"sysctls : \"vm.max_map_count\" : 262144","title":"sysctl"},{"location":"systemd/","text":"","title":"Systemd"},{"location":"template/","text":"Files & Templates files files : /etc/some/file : file /etc/some/file2 : file2 templates templates : /etc/some/file : file /etc/some/file2 : file2","title":"Templates"},{"location":"template/#files-templates","text":"","title":"Files &amp; Templates"},{"location":"template/#files","text":"files : /etc/some/file : file /etc/some/file2 : file2","title":"files"},{"location":"template/#templates","text":"templates : /etc/some/file : file /etc/some/file2 : file2","title":"templates"},{"location":"targets/ansible/","text":"Ansible Option Description Support files Map of files to copy native copy module templates Map of templates to render native template module containers List of containers to exectute docker_systemd_service role commands List of commands to execute. native shell module mounts Map of NFS mounts native fstab module sysctls Sysctl variables to set native sysctl module env_vars Environment variables to set /etc/environment","title":"Ansible"},{"location":"targets/ansible/#ansible","text":"Option Description Support files Map of files to copy native copy module templates Map of templates to render native template module containers List of containers to exectute docker_systemd_service role commands List of commands to execute. native shell module mounts Map of NFS mounts native fstab module sysctls Sysctl variables to set native sysctl module env_vars Environment variables to set /etc/environment","title":"  Ansible"},{"location":"targets/cloudinit/","text":"Cloud init The cloudinit target will generate a config locally suitable for use in tools like AWS User Data etc. Supported Arguments Option Description Support files Map of files to copy Yes templates Map of templates to render Yes containers List of containers to exectute \u2716 load_balancers List of load balancers \u2716 commands List of commands to execute. Yes mounts Map of NFS mounts Yes sysctls Sysctl variables to set Yes env_vars Environment variables to set Yes","title":"<img src=\"../../images/cloudinit.png\" height=24> Cloud init"},{"location":"targets/cloudinit/#cloud-init","text":"The cloudinit target will generate a config locally suitable for use in tools like AWS User Data etc.","title":" Cloud init"},{"location":"targets/cloudinit/#supported-arguments","text":"Option Description Support files Map of files to copy Yes templates Map of templates to render Yes containers List of containers to exectute \u2716 load_balancers List of load balancers \u2716 commands List of commands to execute. Yes mounts Map of NFS mounts Yes sysctls Sysctl variables to set Yes env_vars Environment variables to set Yes","title":"Supported Arguments"},{"location":"targets/ecs/","text":"AWS ECS Supported Arguments Option Description Support files Map of files to copy \u2716 templates Map of templates to render \u2716 containers List of containers to exectute Uses ECS Services/Tasks load_balancers List of load balancers Uses Application Load Balancers commands List of commands to execute. \u2716 mounts Map of NFS mounts \u2716 sysctls Sysctl variables to set \u2716 env_vars Environment variables to set \u2716 Use container environment instead Extra Arguments Argument Default Description cluster_name account_id AWS Account ID domain_id Route53 Domain ID domain region AWS Region cluster_size 3 Initial size of Auto Scaling Group docker_registry {{account_id}}.dkr.ecr.{{region}}.amazonaws.com log_retention 7 Number of days to retain CloudWatch logs ssh_key_name default_ssl_arn ecs_instance_type c4.xlarge ecs_image_id ami-0254e5972ebcd132c ECS AMI Image ID subnet_name APP Subnet prefix to place ECS instances into","title":"AWS ECS"},{"location":"targets/ecs/#aws-ecs","text":"","title":" AWS ECS"},{"location":"targets/ecs/#supported-arguments","text":"Option Description Support files Map of files to copy \u2716 templates Map of templates to render \u2716 containers List of containers to exectute Uses ECS Services/Tasks load_balancers List of load balancers Uses Application Load Balancers commands List of commands to execute. \u2716 mounts Map of NFS mounts \u2716 sysctls Sysctl variables to set \u2716 env_vars Environment variables to set \u2716 Use container environment instead","title":"Supported Arguments"},{"location":"targets/ecs/#extra-arguments","text":"Argument Default Description cluster_name account_id AWS Account ID domain_id Route53 Domain ID domain region AWS Region cluster_size 3 Initial size of Auto Scaling Group docker_registry {{account_id}}.dkr.ecr.{{region}}.amazonaws.com log_retention 7 Number of days to retain CloudWatch logs ssh_key_name default_ssl_arn ecs_instance_type c4.xlarge ecs_image_id ami-0254e5972ebcd132c ECS AMI Image ID subnet_name APP Subnet prefix to place ECS instances into","title":"Extra Arguments"}]}